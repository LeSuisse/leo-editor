import ast
import unittest
from typing import Any, Dict, List

v1: Any
v2: Any
junk1: Any
junk2: Any
junk3: Any
py_version: Any
has_async_tokens: Any

class LeoGlobals:
    def adjustTripleString(self, s): ...
    def callerName(self, n): ...
    def callers(self, n: int = ...): ...
    def es_exception(self, full: bool = ...): ...
    def getLastTracebackFileAndLineNumber(self): ...
    def objToString(self, obj, tag: Any | None = ...): ...
    def pdb(self) -> None: ...
    def plural(self, obj): ...
    def printObj(self, obj, tag: Any | None = ...) -> None: ...
    def splitLines(self, s): ...
    def toEncodedString(self, s, encoding: str = ...): ...
    def toUnicode(self, s: Any, encoding: str = ...) -> str: ...
    def trace(self, *args) -> None: ...
    def truncate(self, s, n): ...

def fstringify_command(files) -> None: ...
def fstringify_diff_command(files) -> None: ...
def orange_command(files) -> None: ...
def orange_diff_command(files) -> None: ...
def main() -> None: ...
def regularize_nls(s): ...

encoding_pattern: Any

def get_encoding_directive(bb): ...
def read_file(filename, encoding: str = ...): ...
def read_file_with_encoding(filename): ...
def strip_BOM(bb): ...
def write_file(filename, s, encoding: str = ...) -> None: ...
def find_anchor_token(node, global_token_list): ...
def find_paren_token(i, global_token_list): ...
def get_node_token_list(node, global_tokens_list): ...
def is_significant(kind, value): ...
def is_significant_token(token): ...
def match_parens(filename, i, j, tokens): ...
def tokens_for_node(filename, node, global_token_list): ...
def tokens_to_string(tokens): ...
def compare_asts(ast1, ast2): ...
def compare_lists(list1, list2): ...
def expected_got(expected, got): ...
def get_time(): ...
def obj_id(obj): ...
def op_name(node): ...
def make_tokens(contents): ...
def parse_ast(s): ...
def dump_ast(ast, tag: str = ...) -> None: ...
def dump_contents(contents, tag: str = ...) -> None: ...
def dump_lines(tokens, tag: str = ...) -> None: ...
def dump_results(tokens, tag: str = ...) -> None: ...
def dump_tokens(tokens, tag: str = ...) -> None: ...
def dump_tree(tokens, tree, tag: str = ...) -> None: ...
def show_diffs(s1, s2, filename: str = ...) -> None: ...
def find_statement_node(node): ...
def is_ancestor(node, token): ...
def is_long_statement(node): ...
def is_statement_node(node): ...
def nearest_common_ancestor(node1, node2): ...
def add_token_to_token_list(token, node) -> None: ...
def replace_node(new_node, old_node) -> None: ...
def replace_token(token, kind, value) -> None: ...

class AssignLinksError(Exception): ...
class AstNotEqual(Exception): ...
class FailFast(Exception): ...

class TokenOrderGenerator:
    n_nodes: int
    def balance_tokens(self, tokens): ...
    file_name: Any
    level: int
    node: Any
    tokens: Any
    tree: Any
    def create_links(self, tokens, tree, file_name: str = ...) -> None: ...
    filename: Any
    def init_from_file(self, filename): ...
    def init_from_string(self, contents, filename): ...
    begin_end_stack: List[str]
    node_index: int
    node_stack: List[ast.AST]
    def begin_visitor(self, node) -> None: ...
    def end_visitor(self, node) -> None: ...
    def find_next_significant_token(self): ...
    def gen(self, z) -> None: ...
    def gen_name(self, val) -> None: ...
    def gen_op(self, val) -> None: ...
    def gen_token(self, kind, val) -> None: ...
    px: int
    def sync_token(self, kind, val) -> None: ...
    last_statement_node: Any
    def set_links(self, node, token) -> None: ...
    def sync_name(self, val) -> None: ...
    def sync_op(self, val) -> None: ...
    def visitor(self, node) -> None: ...
    def do_keyword(self, node) -> None: ...
    def do_arg(self, node) -> None: ...
    def do_arguments(self, node) -> None: ...
    def do_AsyncFunctionDef(self, node) -> None: ...
    def do_ClassDef(self, node, print_body: bool = ...) -> None: ...
    def do_FunctionDef(self, node) -> None: ...
    def do_Interactive(self, node) -> None: ...
    def do_Lambda(self, node) -> None: ...
    def do_Module(self, node) -> None: ...
    def do_Expr(self, node) -> None: ...
    def do_Expression(self, node) -> None: ...
    def do_GeneratorExp(self, node) -> None: ...
    def do_NamedExpr(self, node) -> None: ...
    def do_Attribute(self, node) -> None: ...
    def do_Bytes(self, node) -> None: ...
    def do_comprehension(self, node) -> None: ...
    def do_Constant(self, node) -> None: ...
    def do_Dict(self, node) -> None: ...
    def do_DictComp(self, node) -> None: ...
    def do_Ellipsis(self, node) -> None: ...
    def do_ExtSlice(self, node) -> None: ...
    def do_Index(self, node) -> None: ...
    def do_FormattedValue(self, node) -> None: ...
    def do_JoinedStr(self, node) -> None: ...
    def do_List(self, node) -> None: ...
    def do_ListComp(self, node) -> None: ...
    def do_Name(self, node) -> None: ...
    def do_NameConstant(self, node) -> None: ...
    def do_Num(self, node) -> None: ...
    def do_Set(self, node) -> None: ...
    def do_SetComp(self, node) -> None: ...
    def do_Slice(self, node) -> None: ...
    def do_Str(self, node) -> None: ...
    def get_concatenated_string_tokens(self): ...
    def do_Subscript(self, node) -> None: ...
    def do_Tuple(self, node) -> None: ...
    def do_BinOp(self, node) -> None: ...
    def do_BoolOp(self, node) -> None: ...
    def do_Compare(self, node) -> None: ...
    def do_UnaryOp(self, node) -> None: ...
    def do_IfExp(self, node) -> None: ...
    def do_Starred(self, node) -> None: ...
    def do_AnnAssign(self, node) -> None: ...
    def do_Assert(self, node) -> None: ...
    def do_Assign(self, node) -> None: ...
    def do_AsyncFor(self, node) -> None: ...
    def do_AsyncWith(self, node) -> None: ...
    def do_AugAssign(self, node) -> None: ...
    def do_Await(self, node) -> None: ...
    def do_Break(self, node) -> None: ...
    def do_Call(self, node) -> None: ...
    def arg_helper(self, node) -> None: ...
    def handle_call_arguments(self, node): ...
    def do_Continue(self, node) -> None: ...
    def do_Delete(self, node) -> None: ...
    def do_ExceptHandler(self, node) -> None: ...
    def do_For(self, node) -> None: ...
    def do_Global(self, node) -> None: ...
    def do_If(self, node) -> None: ...
    def do_Import(self, node) -> None: ...
    def do_ImportFrom(self, node) -> None: ...
    def do_Nonlocal(self, node) -> None: ...
    def do_Pass(self, node) -> None: ...
    def do_Raise(self, node) -> None: ...
    def do_Return(self, node) -> None: ...
    def do_Try(self, node) -> None: ...
    def do_While(self, node) -> None: ...
    def do_With(self, node) -> None: ...
    def do_Yield(self, node) -> None: ...
    def do_YieldFrom(self, node) -> None: ...

class TokenOrderTraverser:
    last_node_index: int
    def traverse(self, tree): ...
    def visit(self, node) -> None: ...

class Orange:
    black_mode: bool
    nobeautify_pat: Any
    node_pat: Any
    start_doc_pat: Any
    at_others_pat: Any
    end_doc_pat: Any
    allow_joined_strings: bool
    max_join_line_length: int
    max_split_line_length: int
    tab_width: int
    def __init__(self, settings: Any | None = ...) -> None: ...
    def push_state(self, kind, value: Any | None = ...) -> None: ...
    def oops(self) -> None: ...
    curly_brackets_level: int
    decorator_seen: bool
    in_arg_list: int
    level: int
    lws: str
    paren_level: int
    square_brackets_stack: Any
    state_stack: Any
    val: Any
    verbatim: bool
    code_list: Any
    code_list_index: int
    tokens: Any
    tree: Any
    token: Any
    def beautify(self, contents, filename, tokens, tree, max_join_line_length: Any | None = ..., max_split_line_length: Any | None = ...): ...
    filename: Any
    def beautify_file(self, filename): ...
    def beautify_file_diff(self, filename): ...
    in_doc_part: bool
    def do_comment(self) -> None: ...
    def do_encoding(self) -> None: ...
    def do_endmarker(self) -> None: ...
    def do_dedent(self) -> None: ...
    def do_indent(self) -> None: ...
    def handle_dedent_after_class_or_def(self, kind) -> None: ...
    def do_name(self) -> None: ...
    def do_newline(self) -> None: ...
    def do_nl(self) -> None: ...
    def do_number(self) -> None: ...
    def do_op(self) -> None: ...
    def do_string(self) -> None: ...
    beautify_pat: Any
    def do_verbatim(self) -> None: ...
    def do_ws(self) -> None: ...
    def add_line_end(self): ...
    def add_token(self, kind, value): ...
    def blank(self) -> None: ...
    def blank_lines(self, n) -> None: ...
    def clean(self, kind) -> None: ...
    def clean_blank_lines(self): ...
    def colon(self, val): ...
    def line_end(self) -> None: ...
    def line_indent(self) -> None: ...
    def lt(self, val) -> None: ...
    def rt(self, val) -> None: ...
    def possible_unary_op(self, s) -> None: ...
    def unary_op(self, s) -> None: ...
    def star_op(self) -> None: ...
    def star_star_op(self) -> None: ...
    def word(self, s) -> None: ...
    def word_op(self, s) -> None: ...
    def split_line(self, node, token): ...
    def append_tail(self, prefix, tail) -> None: ...
    def find_prev_line(self): ...
    def find_line_prefix(self, token_list): ...
    def join_lines(self, node, token) -> None: ...

class OrangeSettings: ...

class ParseState:
    kind: Any
    value: Any
    def __init__(self, kind, value) -> None: ...

class BaseTest(unittest.TestCase):
    counts: Dict[str, int]
    times: Dict[str, float]
    debug: Any
    def adjust_expected(self, s): ...
    def check_roundtrip(self, contents) -> None: ...
    link_error: bool
    tog: Any
    def make_data(self, contents, description: Any | None = ...): ...
    def make_file_data(self, filename): ...
    def make_tokens(self, contents): ...
    def make_tree(self, contents): ...
    def balance_tokens(self, tokens): ...
    def create_links(self, tokens, tree, filename: str = ...) -> None: ...
    def fstringify(self, contents, tokens, tree, filename: Any | None = ..., silent: bool = ...): ...
    code_list: Any
    def beautify(self, contents, tokens, tree, filename: Any | None = ..., max_join_line_length: Any | None = ..., max_split_line_length: Any | None = ...): ...
    def dump_stats(self) -> None: ...
    def dump_counts(self) -> None: ...
    def dump_times(self) -> None: ...
    def update_counts(self, key, n) -> None: ...
    def update_times(self, key, t) -> None: ...

class AstDumper:
    tokens: Any
    def dump_tree(self, tokens, tree): ...
    def dump_tree_and_links_helper(self, node, level, result) -> None: ...
    def compute_node_string(self, node, level): ...
    def show_fields(self, class_name, node, truncate_n): ...
    def show_line_range(self, node): ...
    def show_tokens(self, node, n, m, show_cruft: bool = ...): ...
    def show_header(self): ...
    annotate_fields: bool
    include_attributes: bool
    indent_ws: str
    def dump_ast(self, node, level: int = ...): ...
    def get_fields(self, node): ...

class Optional_TestFiles(BaseTest):
    def test_leoApp(self) -> None: ...
    def test_leoAst(self) -> None: ...
    def test_leoDebugger(self) -> None: ...
    def test_leoFind(self) -> None: ...
    def test_leoGlobals(self) -> None: ...
    def test_leoTips(self) -> None: ...
    def test_runLeo(self) -> None: ...
    kind: Any
    value: Any
    node_list: Any
    def compare_tog_vs_asttokens(self): ...

class TestFstringify(BaseTest):
    def test_bug_1851(self) -> None: ...
    def test_crash_1(self) -> None: ...
    def test_crash_2(self) -> None: ...
    def show_message(self) -> None: ...
    def test_braces(self) -> None: ...
    def test_backslash_in_expr(self) -> None: ...
    def test_call_in_rhs(self) -> None: ...
    def test_call_in_rhs_2(self) -> None: ...
    def test_call_with_attribute(self) -> None: ...
    def test_call_with_comments(self) -> None: ...
    def test_change_quotes(self) -> None: ...
    def test_complex_rhs(self) -> None: ...
    def test_function_call(self) -> None: ...
    def test_ImportFrom(self) -> None: ...
    def test_ListComp(self) -> None: ...
    def test_munge_spec(self) -> None: ...
    def test_newlines(self) -> None: ...
    def test_parens_in_rhs(self) -> None: ...
    def test_single_quotes(self) -> None: ...
    def test_switch_quotes(self) -> None: ...
    def test_switch_quotes_2(self) -> None: ...
    def test_switch_quotes_3(self) -> None: ...
    def test_switch_quotes_fail(self) -> None: ...

class TestOrange(BaseTest):
    def blacken(self, contents, line_length: Any | None = ...): ...
    def test_bug_1429(self) -> None: ...
    def test_bug_1851(self) -> None: ...
    def test_at_doc_part(self) -> None: ...
    def test_backslash_newline(self) -> None: ...
    def test_blank_lines_after_function(self) -> None: ...
    def test_blank_lines_after_function_2(self) -> None: ...
    def test_blank_lines_after_function_3(self) -> None: ...
    def test_decorator(self) -> None: ...
    def test_dont_delete_blank_lines(self) -> None: ...
    def test_function_defs(self) -> None: ...
    def test_indented_comment(self) -> None: ...
    def test_join_and_strip_condition(self) -> None: ...
    def test_join_leading_whitespace(self) -> None: ...
    def test_join_lines(self) -> None: ...
    def test_join_suppression(self) -> None: ...
    def test_join_too_long_lines(self) -> None: ...
    def test_leo_sentinels_1(self) -> None: ...
    def test_leo_sentinels_2(self) -> None: ...
    def test_lines_before_class(self) -> None: ...
    def test_multi_line_pet_peeves(self) -> None: ...
    def test_one_line_pet_peeves(self) -> None: ...
    def test_return(self) -> None: ...
    def test_single_quoted_string(self) -> None: ...
    def test_split_lines(self) -> None: ...
    def test_split_lines_2(self) -> None: ...
    def test_split_lines_3(self) -> None: ...
    def test_sync_tokens(self) -> None: ...
    def test_ternary(self) -> None: ...
    def test_verbatim(self) -> None: ...
    def test_verbatim2(self) -> None: ...
    def test_verbatim_with_pragma(self) -> None: ...

class TestReassignTokens(BaseTest):
    def test_reassign_tokens(self) -> None: ...
    def test_nearest_common_ancestor(self) -> None: ...

class TestTOG(BaseTest):
    debug: Any
    def test_full_grammar(self) -> None: ...
    def test_bug_1851(self) -> None: ...
    def test_line_315(self) -> None: ...
    def test_line_337(self) -> None: ...
    def test_line_483(self) -> None: ...
    def test_line_494(self) -> None: ...
    def test_line_875(self) -> None: ...
    def test_line_898(self) -> None: ...
    def test_walrus_operator(self) -> None: ...
    def test_ClassDef(self) -> None: ...
    def test_ClassDef2(self) -> None: ...
    def test_FunctionDef(self) -> None: ...
    def test_FunctionDef_with_annotations(self) -> None: ...
    def test_attribute(self) -> None: ...
    def test_CompareOp(self) -> None: ...
    def test_Dict(self) -> None: ...
    def test_Dict_2(self) -> None: ...
    def test_DictComp(self) -> None: ...
    def test_ExtSlice(self) -> None: ...
    def test_ListComp(self) -> None: ...
    def test_NameConstant(self) -> None: ...
    def test_op_semicolon(self) -> None: ...
    def test_op_semicolon2(self) -> None: ...
    def test_Set(self) -> None: ...
    def test_SetComp(self) -> None: ...
    def test_UnaryOp(self) -> None: ...
    def test_fstring1(self) -> None: ...
    def test_fstring2(self) -> None: ...
    def test_fstring3(self) -> None: ...
    def test_fstring4(self) -> None: ...
    def test_fstring5(self) -> None: ...
    def test_fstring6(self) -> None: ...
    def test_fstring7(self) -> None: ...
    def test_fstring8(self) -> None: ...
    def test_fstring9(self) -> None: ...
    def test_fstring10(self) -> None: ...
    def test_fstring11(self) -> None: ...
    def test_fstring12(self) -> None: ...
    def test_fstring13(self) -> None: ...
    def test_fstring14(self) -> None: ...
    def test_fstring15(self) -> None: ...
    def test_fstring16(self) -> None: ...
    def test_regex_fstring(self) -> None: ...
    def test_if1(self) -> None: ...
    def test_if2(self) -> None: ...
    def test_if3(self) -> None: ...
    def test_if4(self) -> None: ...
    def test_if5(self) -> None: ...
    def test_if6(self) -> None: ...
    def test_if7(self) -> None: ...
    def test_if8(self) -> None: ...
    def test_if9(self) -> None: ...
    def test_if10(self) -> None: ...
    def test_comment_in_set_links(self) -> None: ...
    def test_ellipsis_1(self) -> None: ...
    def test_ellipsis_2(self) -> None: ...
    def test_end_of_line(self) -> None: ...
    def test_escapes(self) -> None: ...
    def test_backslashes(self) -> None: ...
    def test_bs_nl(self) -> None: ...
    def test_bytes(self) -> None: ...
    def test_empyt_string(self) -> None: ...
    def test_escaped_delims(self) -> None: ...
    def test_escaped_strings(self) -> None: ...
    def test_fstring_join(self) -> None: ...
    def test_potential_fstring(self) -> None: ...
    def test_raw_docstring(self) -> None: ...
    def test_raw_escapes(self) -> None: ...
    def test_single_quote(self) -> None: ...
    def test_concatenation_1(self) -> None: ...
    def test_string_concatenation_2(self) -> None: ...
    def test_AnnAssign(self) -> None: ...
    def test_AsyncFor(self) -> None: ...
    def test_AsyncFunctionDef(self) -> None: ...
    def test_AsyncWith(self) -> None: ...
    def test_Call(self) -> None: ...
    def test_Delete(self) -> None: ...
    def test_For(self) -> None: ...
    def test_Global(self) -> None: ...
    def test_ImportFrom(self) -> None: ...
    def test_ImportFromStar(self) -> None: ...
    def test_Lambda(self) -> None: ...
    def test_Nonlocal(self) -> None: ...
    def test_Try(self) -> None: ...
    def test_Try2(self) -> None: ...
    def test_While(self) -> None: ...
    def test_With(self) -> None: ...
    def test_Yield(self) -> None: ...
    def test_YieldFrom(self) -> None: ...
    def test_aaa(self) -> None: ...
    def test_zzz(self) -> None: ...

class TestTokens(BaseTest):
    kind: Any
    value: Any
    node_list: Any
    def show_asttokens_script(self): ...
    def show_example_dump(self) -> None: ...
    def test_bs_nl_tokens(self) -> None: ...
    def test_continuation_1(self) -> None: ...
    def test_continuation_2(self) -> None: ...
    def test_continuation_3(self) -> None: ...
    def test_string_concatentation_1(self) -> None: ...
    def test_string_concatentation_2(self) -> None: ...
    def test_string_concatentation_3(self) -> None: ...
    def test_visitors_exist(self) -> None: ...

class TestTopLevelFunctions(BaseTest):
    def test_get_encoding_directive(self) -> None: ...
    def test_strip_BOM(self) -> None: ...

class TestTOT(BaseTest):
    def test_traverse(self) -> None: ...

class Fstringify(TokenOrderTraverser):
    silent: bool
    filename: Any
    tokens: Any
    tree: Any
    def fstringify(self, contents, filename, tokens, tree): ...
    def fstringify_file(self, filename): ...
    def fstringify_file_diff(self, filename): ...
    def fstringify_file_silent(self, filename): ...
    line_number: Any
    line: Any
    def make_fstring(self, node) -> None: ...
    ws_pat: Any
    def clean_ws(self, s): ...
    def compute_result(self, lt_s, tokens): ...
    def check_back_slashes(self, lt_s, tokens): ...
    def change_quotes(self, lt_s, aList): ...
    def munge_spec(self, spec): ...
    format_pat: Any
    def scan_format_string(self, s): ...
    add_trailing_ws: bool
    def scan_for_values(self): ...
    def scan_rhs(self, node): ...
    def substitute_values(self, lt_s, specs, values): ...
    def message(self, message) -> None: ...
    def replace(self, node, s, values) -> None: ...
    def visit(self, node) -> None: ...

class ReassignTokens(TokenOrderTraverser):
    filename: Any
    tokens: Any
    tree: Any
    def reassign(self, filename, tokens, tree) -> None: ...
    def visit(self, node) -> None: ...

class Token:
    kind: Any
    value: Any
    five_tuple: Any
    index: int
    line: str
    line_number: int
    level: int
    node: Any
    def __init__(self, kind, value) -> None: ...
    def to_string(self): ...
    def brief_dump(self): ...
    def dump(self): ...
    def dump_header(self) -> None: ...
    def error_dump(self): ...
    def show_val(self, truncate_n): ...

class Tokenizer:
    token_index: int
    prev_line_token: Any
    def add_token(self, kind, five_tuple, line, s_row, value) -> None: ...
    def check_results(self, contents) -> None: ...
    lines: Any
    def create_input_tokens(self, contents, tokens): ...
    header_has_been_shown: bool
    prev_offset: Any
    def do_token(self, contents, five_tuple) -> None: ...

g: Any
